{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "experienced-spencer",
   "metadata": {},
   "source": [
    "## 크롤링 기초다루기 \n",
    "### 웹 크롤링이란?\n",
    "#### 0712 memo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-military",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "several-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터가 어떤 의미를 갖고 있는가?? 숨은 인사이트를 찾아내야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-stockholm",
   "metadata": {},
   "source": [
    "### 데이터의 종류\n",
    "\n",
    "- 정형 데이터 - 숫자, 표로 정리할 수 있는 데이터 \n",
    "- 비 정형 데이터 - 문자, 표 형태가 아닌 데이터 \n",
    "\n",
    "결국 중요한건 ,,, 데이터를 수집할 수 있는 능력이 필요하다!  \n",
    "데이터가 없으면 ,,, 분석 자체를 못하니까 ,, 호호\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "쿠팡은 공부하기 좋음 / 네이버 / 뉴스 -> 자동 크롤링을 막아둠 ,, \n",
    "\n",
    "selenium은 특정요소만을 가지고 오는게 아니라 전체 다 가지고 옴 / 웹페이저 코드를 긁음 (이게 전체라는 것) ->\n",
    "특정요소는 beautiful soup가 전체 데이터 중 원하는 부분만 골라서 저장하는 것 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "architectural-mistake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Oldcar\\\\anaconda3\\\\envs\\\\py38r40\\\\lib\\\\site-packages\\\\chromedriver_autoinstaller\\\\91\\\\chromedriver.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromedriver_autoinstaller\n",
    "chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "연습문제 : 경남대 홈페이지에서 오른쪽 상단 검색을 클릭하고 \"장학금\"을 입력하고 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "immune-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "경남대 홈페이지에서 장학생 검색하기\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요 :  df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"경남대 홈페이지에서 장학생 검색하기\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "query_txt = input(\"검색어를 입력하세요 : \")\n",
    "print(\"\\n\")\n",
    "\n",
    "chrome_path = \"C:/data/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "\n",
    "url = \"https://www.kyungnam.ac.kr/sites/ko/index.do\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "element = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div/div[3]/ul/li[1]/a') #여기쪽이 안됨\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div[1]/div/div[3]/ul/li[1]/a').click()\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-fantasy",
   "metadata": {},
   "source": [
    "## beautiful Soup 사용법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-location",
   "metadata": {},
   "source": [
    "위 패키지로 '웹 페이지의 데이터를 가져온다'는 것은 '웹 페이지의 HTML 태그를 가져온다'라는 것과 같다. \n",
    "\n",
    "그럼 bs4로 특정 태그를 가져오기위해서는 find(),find_all()/ select() 함수를 사용한다. \n",
    "\n",
    "전체 데이터에서 찾는게 2개 이상이면 find 경로를 세세하게 다 구해야한다. \n",
    "\n",
    "하지만 ,, 전체 데이터에 유일한 값을 찾는다면 그것만 find('')하면 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-journalist",
   "metadata": {},
   "source": [
    "HTML 코드의 구조도 위의 회사 조직도와 비슷하게 계층으로 이루어져 있다. \n",
    "\n",
    "- find() 쓰는법\n",
    "\n",
    "< div class = 'title'>\n",
    "<태그  `속성 = \"속성값\"`>\n",
    "\n",
    "위 태그를 찾고 싶다면 \n",
    "\n",
    "find('태그명', '속성값')\n",
    "\n",
    "find('div','title') = find('div',class_='title') # 굳이 class_를 쓰지 않아도 되지만 해석하기 좋다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "상위 태그를 가지고 오면 자동으로 하위 태그는 다 가지고 온다. \n",
    "\n",
    "find('영업부').find('영업1팀').find('홍길동')\n",
    "\n",
    "동급이면 들여쓰기가 같다. (즉 위치가 비슷하다는것)\n",
    "\n",
    "<a href = 'dfdfdf'>\n",
    "\n",
    "a가 태그명 'dfdfdf'가 속성값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 사장실 조직도 \n",
    "<같은 동급에 태그가 같다면 상위 태그를 불러와야함 (상위 태그는 ,,, 들여쓰기를 잘봐야함)\n",
    "\n",
    "find('p','title)').find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "find함수에서는 가장 먼저 찾은 데이터를 가지고 온다. \n",
    "\n",
    "핫 스트링 = 셀리니엄으로 얻은 소스코드를 공부 시키는 것 \n",
    "\n",
    "원래 html 코드를 가져다 주는 것 \n",
    "soup = BeautifulSoup(ex1, 'html.parser')\n",
    "soup.find('title')\n",
    "\n",
    "\n",
    "soup.find('div','name').get_text() #저 태그 안에 있는 내용(문자)만 가지고 온다. \n",
    "\n",
    "데이터 많으면 ,, for문을 돌려서 가지공 오거라 ,, 허허허헣\n",
    "\n",
    "속성값이 여러개 있는지 확인하는 방법은 \n",
    "속성값을 더블클릭한 뒤 \n",
    "컨 + F 한 뒤에 \n",
    "거기에 검색 넣으면 match에 몇개 나오는지 알 수 있다~~~\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
